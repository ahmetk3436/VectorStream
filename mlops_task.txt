VectorStream: Gerçek Zamanlı E-Ticaret
Davranış Analizi Pipeline&#39;ı
Genel Bakış
Bu ödevde, gerçek zamanlı bir veri işleme pipeline&#39;ı tasarlayıp implement etmeniz
beklenmektedir. Sistem, Kafka&#39;dan gelen event&#39;leri okuyacak, bunları embedding&#39;e
dönüştürecek ve Qdrant vektör veritabanına kaydedecektir.
Senaryo
Bir e-ticaret platformu için müşteri davranışlarını gerçek zamanlı analiz eden bir sistem
geliştirmeniz gerekiyor. Sistem şu özelliklere sahip olmalı:
 Kafka&#39;dan gelen müşteri etkileşim event&#39;lerini okuma
 Event&#39;lerdeki metin verilerini (ürün açıklamaları) embedding&#39;e dönüştürme
 Embedding&#39;leri Qdrant&#39;a kaydetme
 Yüksek performans ve ölçeklenebilirlik

Teknik Gereksinimler
1. Teknoloji Stack&#39;i
 Apache Spark: Veri işleme için (Structured Streaming kullanılmalı)
 RAPIDS: GPU hızlandırmalı veri işleme için
 Kafka: Event streaming için
 Qdrant: Vektör veritabanı
 Docker Compose: Tüm servislerin orkestrayonu
 Python: Ana programlama dili
2. Event Yapısı
json
{

&quot;event_id&quot;: &quot;uuid&quot;,
&quot;timestamp&quot;: &quot;2024-01-15T10:30:00Z&quot;,
&quot;user_id&quot;: &quot;user123&quot;,
&quot;event_type&quot;: &quot;purchase&quot;,
&quot;product&quot;: {
&quot;id&quot;: &quot;uuid&quot;,
&quot;name&quot;: &quot;Ürün Adı&quot;,
&quot;description&quot;: &quot;Detaylı ürün açıklaması...&quot;,
&quot;category&quot;: &quot;Elektronik&quot;,
&quot;price&quot;: 1299.99
},
&quot;session_id&quot;: &quot;session789&quot;
}
3. Pipeline Gereksinimleri
a) Kafka Consumer
 Spark Structured Streaming kullanarak Kafka&#39;dan veri okuma
 Batch interval: 10 saniye
 Hata yönetimi ve retry mekanizması
b) Embedding İşlemi
 Ürün açıklamalarını embedding&#39;e dönüştürme
 Sentence Transformers veya benzeri bir model kullanma
 RAPIDS cuML ile GPU hızlandırması (opsiyonel ama tercih edilir)

c) Qdrant Entegrasyonu
 Batch halinde embedding&#39;leri Qdrant&#39;a yazma
 Collection yapısı tasarımı
 Metadata ile birlikte saklama
4. Performans Kriterleri
 Saniyede en az 1000 event işleyebilmeli
 End-to-end latency &lt; 30 saniye
 Memory-efficient olmalı

 GPU kullanımı optimize edilmeli (RAPIDS kullanılıyorsa)
Beklenen Çıktılar
1. Kod Deposu
Aşağıdaki yapıda bir GitHub repository&#39;si:
mlops-streaming-pipeline/
├── docker-compose.yml
├── requirements.txt
├── README.md
├── src/
│ ├── __init__.py
│ ├── kafka_consumer.py
│ ├── embedding_processor.py
│ ├── qdrant_writer.py
├── config/
│ ├── spark_config.py
│ └── app_config.yaml
├── tests/
│ ├── test_consumer.py
│ ├── test_embedding.py
│ └── test_integration.py
└── scripts/
├── generate_sample_data.py
└── performance_test.py

2. Docker Compose Yapısı
docker-compose.yaml
version: &#39;3.8&#39;
services:
zookeeper:
# Zookeeper config

kafka:
# Kafka config
qdrant:
# Qdrant config
spark-app:
# Spark application
# RAPIDS desteği eklenebilir
3. Dokümantasyon
README.md İçeriği:
 Proje açıklaması
 Kurulum adımları
 Çalıştırma talimatları
 Mimari diyagram
 Performans test sonuçları
Değerlendirme Kriterleri
1. Kod Kalitesi (25%)
 Clean code prensipleri
 Modüler yapı
 Error handling
2. Performans (25%)
 Belirtilen performans kriterlerini karşılama
 Resource kullanımı optimizasyonu
 RAPIDS entegrasyonu (bonus)
3. Sistem Tasarımı (20%)
 Mimari kararlar
 Ölçeklenebilirlik
 Fault tolerance

 Monitoring stratejisi
4. DevOps Pratikleri (20%)
 Docker Compose yapısı
 Environment yönetimi
 Deployment stratejisi
5. Dokümantasyon (10%)
 README kalitesi
 Kod içi dokümantasyon
 Mimari diyagramlar
 Setup kolaylığı
Teslim Süresi
 Süre: 5-7 gün
 Teslim Formatı: Zip olarak mail aracılığı ile gönderilecek.
 Demo: 15 dakikalık Sunum ve 15 dakika Q&amp;A seansı

Not: Bu ödev, gerçek dünya MLOps problemlerini simüle etmektedir. Mükemmel bir
çözüm beklemiyoruz, ancak düşünce sürecinizi, trade-off&#39;ları nasıl değerlendirdiğinizi ve
karmaşık sistemleri nasıl tasarladığınızı görmek istiyoruz.