kafka:
  bootstrap_servers: "127.0.0.1:9092"
  topic: "ecommerce-events"
  group_id: "vectorstream-consumer"
  auto_offset_reset: "latest"
  batch_size: 5000
  max_poll_records: 20000
  partitions: 16
  replication_factor: 1
  auto_create_topic: true
  auto_configure_partitions: true
  consumer:
    fetch_max_bytes: 10485760
    max_poll_records: 10000

qdrant:
  host: "127.0.0.1"
  port: 6334
  collection_name: "ecommerce_embeddings"
  vector_size: 384
  distance: "Cosine"
  timeout: 30
  batch_size: 5000
  batch_timeout: 0.5

spark:
  app_name: "VectorStream-MLOps-Pipeline"
  master: "local[*]"
  spark:
    executor_memory: "8g"
    driver_memory: "4g"
    executor_cores: 8
    max_executors: 16
    streaming:
      batch_interval: 0.5
      max_offsets_per_trigger: 50000
    checkpoint_location: "/tmp/spark-checkpoint-vectorstream"
    trigger_interval: "1 seconds"
    max_offsets_per_trigger: max_offsets_per_trigger
    output_mode: "append"
  kafka:
    starting_offsets: "latest"
    fetch_timeout: 60
    enable_auto_commit: true
  sql:
    adaptive:
      enabled: true
      coalescePartitions:
        enabled: true
    shuffle:
      partitions: 200
  dynamicAllocation:
    enabled: true
    minExecutors: 2
    maxExecutors: 8
    initialExecutors: 4
  packages:
    - "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0"
    - "org.apache.kafka:kafka-clients:3.4.0"
  jars:
    - "https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar"
    - "https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.0/kafka-clients-3.4.0.jar"
    - "https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar"
    - "https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar"

embedding:
  model_name: "all-MiniLM-L6-v2"
  vector_size: 384
  device: "cpu"
  batch_size: 5000
  max_length: 512
  normalize_embeddings: true

rapids:
  enabled: true
  gpu_memory_fraction: 0.8
  cuml_acceleration: true
  embedding:
    device: "cuda"
    batch_size: 64
  performance:
    enable_memory_pool: true
    enable_async_processing: true

performance:
  target_throughput: 5000
  max_latency: 30
  batch_timeout: 0.5
  distributed_threshold: 50
  retry_attempts: 3
  retry_delay: 1
  use_distributed_processing: true
  back_pressure_queue_size: 20000

logging:
  level: "INFO"
  format: "{time} | {level} | {message}"
  file: "logs/vectorstream.log"

monitoring:
  prometheus_port: 9090
  health_check_interval: 30
  metrics:
    enable_custom_metrics: true
    throughput_window: 60
    latency_percentiles: [50, 95, 99]

performance_overrides:
  kafka:
    batch_size: 5000
    max_poll_records: 20000
  qdrant:
    batch_size: 5000
  embedding:
    batch_size: 256