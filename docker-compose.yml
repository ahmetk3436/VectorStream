services:
  kafka:
    image: apache/kafka-native:3.8.0         
    container_name: kafka
    ports:
      - "9092:9092"      
    volumes:
      - kafka-data:/var/lib/kafka/data
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9091"   # localhost yerine servis adı
      # Dinleyiciler (tek satır, katlama operatörü >- ile)
      KAFKA_LISTENERS: >-
        CONTROLLER://0.0.0.0:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: >-
        HOST://localhost:9092,DOCKER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,HOST:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    restart: unless-stopped

  kafka-ui:
    image: ghcr.io/kafbat/kafka-ui:main   # güncel sürüme geçildi
    container_name: kafka-ui
    ports:
      - "8090:8080"  # port çakışması düzeltildi
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9093
    depends_on:
      - kafka
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - newmind
    
  spark-master:
    image: apache/spark:latest         
    container_name: spark-master
    hostname: spark-master
    command: ["/opt/spark/bin/spark-class",
              "org.apache.spark.deploy.master.Master",
              "--host", "spark-master",
              "--port", "7077"]
    env_file:                           
      - ./config/spark/spark-env.sh
    volumes:
      - ./config/spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
      - ./config/spark/spark-env.sh:/opt/spark/conf/spark-env.sh:ro
      - spark-events:/opt/spark/spark-events
      - ./src:/opt/spark/src
    ports:
      - "7077:7077"     
      - "8083:8080" 

  spark-worker-1:
    image: apache/spark:latest
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on: [spark-master]
    command: ["/opt/spark/bin/spark-class",
              "org.apache.spark.deploy.worker.Worker",
              "spark://spark-master:7077"]
    env_file:
      - ./config/spark/spark-env.sh
    volumes:
      - ./src:/opt/spark/src
      - spark-events:/opt/spark/spark-events
      - ./config/spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf:ro
    ports:
      - "8081:8081"  

  spark-history:
    image: apache/spark:latest
    container_name: spark-history
    hostname: spark-history
    depends_on: [spark-master]
    command: ["/opt/spark/bin/spark-class",
              "org.apache.spark.deploy.history.HistoryServer"]
    env_file:
      - ./config/spark/spark-env.sh
    volumes:
      - spark-events:/opt/spark/spark-events
    ports:
      - "18080:18080"  
    networks:
      - newmind

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - newmind

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - newmind
    depends_on:
      - prometheus

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - newmind

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    restart: unless-stopped
    ports:
      - "8082:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - newmind

  # VectorStream Consumer Service  
  vectorstream-consumer:
    build: .
    container_name: vectorstream-consumer
    depends_on:
      - kafka
      - qdrant
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9093
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - PYTHONPATH=/app
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
    networks:
      - newmind
    restart: unless-stopped
    command: python src/main.py

networks:
  newmind:
    driver: bridge

volumes:
  spark-events:
  kafka-data:
  qdrant_storage:
  prometheus_data:
  grafana_data: